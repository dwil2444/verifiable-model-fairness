# Reading List

Title | Author | Conf | Notes | Link
----- | ------ | ---- | ----- | ----
StereoSet: Measuring stereotypical bias in pretrained language models | Moin Nadeem, Anna Bethke, Siva Reddy | ACL 2021 | Stereoset, defining sets | https://arxiv.org/abs/2004.09456
Does Robustness Improve Fairness? Approaching Fairness with Word Substitution Robustness Methods for Text Classification | Yada Pruksachatkun, Satyapriya Krishna, Jwala Dhamala, Rahul Gupta, Kai-Wei Chang | ACL 2021 | robustness w/IBP leads to fairness | https://arxiv.org/abs/2106.10826
Certified Robustness to Adversarial Word Substitutions | Robin Jia, Aditi Raghunathan, Kerem GÃ¶kse, Percy Liang | EMNLP 2019 | IBP w/PyTorch | https://arxiv.org/abs/1909.00986
Stereotyping Norwegian Salmon: An Inventory of Pitfalls in Fairness Benchmark Datasets | Su Lin Blodgett, Gilsinia Lopez, Alexandra Olteanu, Robert Sim, Hanna Wallach | ACL 2021 | most stereotype detection datasets (eg stereoset) are bad | https://aclanthology.org/2021.acl-long.81/f
Challenges in Automated Debiasing for Toxic Language Detection | Xuhui Zhou, Maarten Sap, Swabha Swayamdipta, Noah A. Smith, Yejin Choi | ACL 2021 | more social groups/defining sets | https://arxiv.org/abs/2102.00086
